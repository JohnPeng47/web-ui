from __future__ import annotations

from argparse import Namespace
from typing import Any, List, cast

from sqlalchemy import func

from pentest_bot.db import get_session
from pentest_bot.db.tables.agent import (
    AgentStepORM,
    PentestResultORM,
    get_run,
    get_agent_ctxt,
    create_agent_steps,
)

from scripts.portswigger.data import PORT_SWIGGER_LABS

def process_run_cmd(args: Namespace) -> None:
    if not getattr(args, "mode", None):
        print("[!] --mode is required")

    print(args.mode)

    if args.mode == "label":
        label_steps_cmd(args)
    elif args.mode == "solution":
        label_solution_cmd(args)
    else:
        print(f"[!] Invalid mode: {args.mode}")
        return

def label_solution_cmd(args: Namespace) -> None:
    from src.llm_models import openai_o4_mini
    from pentest_bot.web_exploit.prompts.classify_solution import CheckAgentSol

    """Re-label AgentStep rows for an existing PentestResult or all results in a Run.

    Either ``--run-id`` *or* ``--result-id`` must be supplied.  The original
    steps (group_id=0) are passed through the same `LabelAgentSteps` flow the
    online agent uses.  Labeled rows are stored with a new `group_id` so that
    the original data remain untouched.
    """

    if not getattr(args, "run_id", None) and not getattr(args, "result_id", None):
        print("[!] Either --run-id or --result-id is required")
        return

    step_labeler = CheckAgentSol()
    lm_model = openai_o4_mini()

    with get_session() as session:
        # ------------------------------------------------------------------
        # 1. Collect target PentestResult rows
        # ------------------------------------------------------------------
        results: List[PentestResultORM] = []

        if getattr(args, "run_id", None):
            run = get_run(session, args.run_id)
            if run is None:
                print(f"[!] Run ID {args.run_id} not found")
                return
            results.extend(run.results)

        if getattr(args, "result_id", None):
            res = (
                session.query(PentestResultORM)
                .filter(PentestResultORM.id == args.result_id)
                .first()
            )
            if res is None:
                print(f"[!] PentestResult ID {args.result_id} not found")
                return
            results.append(res)

        if not results:
            print("<no PentestResult rows found>")
            return

        total_labeled = 0
        print(f"[+] Labeling {len(results)} PentestResult row(s)")
        eval_name = results[0].eval_name
        vuln_class, lab_ind = eval_name.rsplit("_", 1)
        solution = PORT_SWIGGER_LABS[vuln_class][int(lab_ind)]["solution"]

        # # ------------------------------------------------------------------
        # # 2. Iterate results – label & persist
        # # ------------------------------------------------------------------
        for res in results:
            ctxt = get_agent_ctxt(session, int(res.id), group_id=0)  # type: ignore[arg-type]
            if not ctxt:
                continue

            agent_steps = ctxt.steps()

            # Invoke the LLM labeler
            try:
                critique = step_labeler.invoke(lm_model, prompt_args={"trace": agent_steps, "success": res.success, "solution": solution})  # type: ignore[arg-type]
                print(critique)
            except Exception as exc:
                print(f"[!] Failed to label steps for result {res.id}: {exc}")
                continue


def label_steps_cmd(args: Namespace) -> None:
    from src.llm_models import openai_o4_mini
    from pentest_bot.web_exploit.prompts.classify_steps import LabelAgentSteps

    """Re-label AgentStep rows for an existing PentestResult or all results in a Run.

    Either ``--run-id`` *or* ``--result-id`` must be supplied.  The original
    steps (group_id=0) are passed through the same `LabelAgentSteps` flow the
    online agent uses.  Labeled rows are stored with a new `group_id` so that
    the original data remain untouched.
    """

    if not getattr(args, "run_id", None) and not getattr(args, "result_id", None):
        print("[!] Either --run-id or --result-id is required")
        return

    step_labeler = LabelAgentSteps()
    lm_model = openai_o4_mini()

    with get_session() as session:
        # ------------------------------------------------------------------
        # 1. Collect target PentestResult rows
        # ------------------------------------------------------------------
        results: List[PentestResultORM] = []

        if getattr(args, "run_id", None):
            run = get_run(session, args.run_id)
            if run is None:
                print(f"[!] Run ID {args.run_id} not found")
                return
            results.extend(run.results)

        if getattr(args, "result_id", None):
            res = (
                session.query(PentestResultORM)
                .filter(PentestResultORM.id == args.result_id)
                .first()
            )
            if res is None:
                print(f"[!] PentestResult ID {args.result_id} not found")
                return
            results.append(res)

        if not results:
            print("<no PentestResult rows found>")
            return

        total_labeled = 0
        print(f"[+] Labeling {len(results)} PentestResult row(s)")

        # ------------------------------------------------------------------
        # 2. Iterate results – label & persist
        # ------------------------------------------------------------------
        for res in results:
            ctxt = get_agent_ctxt(session, int(res.id), group_id=0)  # type: ignore[arg-type]
            if not ctxt:
                continue

            agent_steps = ctxt.steps()

            # Invoke the LLM labeler
            try:
                step_types = step_labeler.invoke(lm_model, prompt_args={"results": agent_steps})  # type: ignore[arg-type]
                step_list_raw = cast(Any, step_types)
            except Exception as exc:
                print(f"[!] Failed to label steps for result {res.id}: {exc}")
                continue

            # Determine next group_id for this result
            max_gid = (
                session.query(func.max(AgentStepORM.group_id))
                .filter(AgentStepORM.pentest_result_id == int(res.id))
                .scalar()
                or 0
            )
            new_gid = max_gid + 1

            # Persist new AgentStep rows with labels and new group_id
            opik_prompt_name, opik_prompt_commit = step_labeler.get_opik_prompt_info()
            create_agent_steps(
                session,
                agent_steps,
                step_list_raw.steps,  # type: ignore[attr-defined]
                int(res.id),
                opik_prompt_name,
                opik_prompt_commit,
                group_id=new_gid,
            )

            total_labeled += 1

        print(f"[+] Labeled steps for {total_labeled} PentestResult row(s). New group_id(s) added.")
        print(f"Total cost: ${lm_model.get_cost():.4f}") 