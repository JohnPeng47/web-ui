from __future__ import annotations

"""Mini parser for step-transition query language.

See `search_steps.py` for usage examples.
"""
from typing import List, Tuple
import math
import re

# ────────────────────────────────────────────────────────────────
# Tokenization helpers
# ────────────────────────────────────────────────────────────────
TOK = re.compile(
    r"\s*([A-Z_]+|->|\(|\)|\[|\]|\{[^{}]+\}|\{|\}|[|&])"
)

# ────────────────────────────────────────────────────────────────
# AST Nodes
# ────────────────────────────────────────────────────────────────
class Node:  # noqa: D401 – simple marker base-class
    """Base class for all AST nodes."""

    def __iter__(self):
        # allow quick traversal utilities (optional)
        yield self


class Seq(Node):
    def __init__(self, parts: List[Node]):
        self.parts = parts

    def __repr__(self) -> str:  # pragma: no cover – debug helper
        return f"Seq({self.parts})"


class Alt(Node):
    def __init__(self, options: List[Node]):
        self.options = options

    def __repr__(self):  # pragma: no cover – debug helper
        return f"Alt({self.options})"


class AndUnordered(Node):
    """Represents unordered-AND group: `{A & B & C}`."""

    def __init__(self, parts: List[Node]):
        self.parts = parts

    def __repr__(self):  # pragma: no cover – debug helper
        return f"AndUnordered({self.parts})"


class Atom(Node):
    def __init__(self, name: str, rep: Tuple[int, float] = (1, 1)):
        self.name = name
        self.rep = rep

    def __repr__(self):  # pragma: no cover – debug helper
        lo, hi = self.rep
        return f"Atom({self.name}, {lo},{hi})"


# ────────────────────────────────────────────────────────────────
# Repetition parser
# ────────────────────────────────────────────────────────────────

def _parse_rep(rep_txt: str) -> Tuple[int, float]:
    """Parse a repetition string like "{3}", "{>2}", "{2,5}" → (lo, hi)."""

    inside = rep_txt[1:-1].strip()
    if inside.isdigit():
        n = int(inside)
        return n, n

    # inequalities first (>=, <=)
    if inside.startswith(">="):
        n = int(inside[2:])
        return n, math.inf
    if inside.startswith("<="):
        n = int(inside[2:])
        return 0, n

    # strict inequalities (>, <)
    if inside.startswith(">"):
        n = int(inside[1:])
        return n + 1, math.inf
    if inside.startswith("<"):
        n = int(inside[1:])
        return 0, n - 1 if n > 0 else 0

    # numeric ranges a,b  /  a,  /  ,b
    if "," in inside:
        lo_str, hi_str = (s.strip() for s in inside.split(",", 1))
        lo = int(lo_str) if lo_str else 0
        hi: float
        if hi_str:
            hi = int(hi_str)
        else:
            hi = math.inf
        return lo, hi

    raise ValueError(f"Bad repetition spec: {rep_txt}")


# ────────────────────────────────────────────────────────────────
# Recursive-descent parser implementation
# ────────────────────────────────────────────────────────────────
class _Parser:
    def __init__(self, text: str):
        self.tokens: List[str] = TOK.findall(text)
        self.i: int = 0

    # basic cursor helpers
    def _peek(self) -> str | None:
        return self.tokens[self.i] if self.i < len(self.tokens) else None

    def _eat(self, tok: str):
        if self._peek() != tok:
            raise ValueError(f"Expected '{tok}', got '{self._peek()}' in pattern query")
        self.i += 1

    # grammar production methods -------------------------------------------------
    def pattern(self) -> Node:
        seq = self.sequence()
        if self._peek() == "->":
            parts: List[Node] = [seq]
            while self._peek() == "->":
                self._eat("->")
                parts.append(self.sequence())
            return Seq(parts)
        return seq

    def sequence(self) -> Node:
        parts: List[Node] = []
        while True:
            tok = self._peek()
            if tok is None or tok in {")", "]", "}", "->", "|", "&"}:
                break
            parts.append(self.term())
        if not parts:
            raise ValueError("Empty sequence in pattern query")
        return parts[0] if len(parts) == 1 else Seq(parts)

    def term(self) -> Node:
        tok = self._peek()
        if tok is None:
            raise ValueError("Unexpected end of pattern")

        # group openers ---------------------------------------------------------
        if tok in ("(", "[", "{"):
            return self.group()

        # atom (token)
        self.i += 1  # consume token
        name = tok
        rep: Tuple[int, float] = (1, 1)
        nxt = self._peek()
        if nxt and nxt.startswith("{") and nxt.endswith("}") and len(nxt) > 2:
            rep = _parse_rep(nxt)
            self.i += 1  # consume repetition token
        return Atom(name, rep)

    def group(self) -> Node:
        opener = self._peek()
        assert opener is not None
        self.i += 1  # consume opener
        if opener == "{":
            sep = "&"
        else:
            sep = "|"
        parts: List[Node] = [self.pattern()]
        while self._peek() == sep:
            self._eat(sep)
            parts.append(self.pattern())
        closer = {
            "(": ")",
            "[": "]",
            "{": "}"
        }[opener]
        self._eat(closer)
        if opener == "{":
            return AndUnordered(parts)
        return Alt(parts) if len(parts) > 1 else parts[0]


# public parse() ---------------------------------------------------------------

def parse(text: str) -> Node:
    """Parse *text* into an AST (root Node)."""

    if not text:
        # caller can treat empty-pattern specially; still return a dummy Seq
        return Seq([])
    return _Parser(text).pattern() 