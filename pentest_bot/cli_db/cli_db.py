from __future__ import annotations

from argparse import ArgumentParser, Namespace
from contextlib import contextmanager, redirect_stdout
from datetime import datetime, timedelta
from importlib import import_module
from pathlib import Path
from typing import Iterable, List, Sequence, Any, cast
from collections import defaultdict
import os

from src.llm_models import openai_o4_mini
from pentest_bot.db import get_session
from pentest_bot.db.tables.agent import (
    AgentStepORM,
    PentestResultORM,
    get_runs_summary,
    get_run,
    get_agent_ctxt,
    get_cost_summary,
    create_agent_steps,
    get_agent_steps,
)
from pentest_bot.web_exploit.utils import get_token_count
from pentest_bot.web_exploit.agent_step import LabelAgentSteps, StepStateAbbr

from .search_steps import search_steps

def _build_table(rows: Sequence[Sequence[str]], headers: Sequence[str] | None = None, max_col: int = 50) -> str:
    """Return an ASCII table as a single string.

    The function calculates column widths from the *longest* cell in each
    column and then draws the grid using ``+``/``-``/``|`` glyphs which render
    correctly even in the Windows 10/11 default console font.
    
    Args:
        rows: The data rows to display
        headers: Optional column headers
        max_col: Maximum width for any column; longer content is truncated with "..."
    """
    if not rows and not headers:
        return "<empty>"

    # Ensure we have at least one row to compute widths
    sample = rows[0] if rows else ["" for _ in headers]  # type: ignore[arg-type]
    col_count = len(headers or sample)

    widths: List[int] = [0] * col_count
    for col_idx in range(col_count):
        header_len = len(headers[col_idx]) if headers else 0  # type: ignore[index]
        max_cell = max((len(r[col_idx]) for r in rows), default=0)
        widths[col_idx] = min(max(header_len, max_cell), max_col)

    def _separator(char: str = "-") -> str:
        return "+" + "+".join(char * (w + 2) for w in widths) + "+"

    def _truncate_cell(cell: str, width: int) -> str:
        if len(cell) <= width:
            return cell
        return cell[:width-3] + "..."

    def _format_row(row: Sequence[str]) -> str:
        return "| " + " | ".join(_truncate_cell(cell, widths[i]).ljust(widths[i]) for i, cell in enumerate(row)) + " |"

    parts: List[str] = [
        _separator(),
    ]
    if headers:
        parts.append(_format_row(headers))
        parts.append(_separator("="))
    for r in rows:
        parts.append(_format_row(r))
        parts.append(_separator())
    return "\n".join(parts)


# ---------------------------------------------------------------------------
# CLI commands
# ---------------------------------------------------------------------------

from sqlalchemy import func, case


def _human_ts(ts: datetime | None) -> str:
    return ts.strftime("%Y-%m-%d %H:%M:%S") if ts else "—"


def list_runs_cmd(args: Namespace) -> None:
    limit = None if args.all else args.limit

    with get_session() as session:
        # REFRACTOR ►  use query helper
        runs = get_runs_summary(session, limit=limit, eval_only=not args.all)

        header_field_mapping = [
            ("ID", "id"),
            ("Created", "created_at"),
            ("Comment", "comment"),
            ("LogDir", "parent_logdir"),
            ("#Results", "total_results"),
            ("#Success", "successes"),
            ("#Steps", "total_steps"),
        ]

        rows = [
            [
                str(r.id),
                _human_ts(r.created_at),
                r.comment or "",
                r.parent_logdir,
                str(int(r.total_results)),
                str(int(r.successes)),
                str(int(r.total_steps or 0)),
            ]
            for r in runs
        ]
        headers = [h for h, _ in header_field_mapping]
        print(_build_table(rows, headers))


# ------------------------------------------------------------------ #
# show-run
# ------------------------------------------------------------------ #
def show_run_cmd(args: Namespace) -> None:
    run_id = args.run_id

    with get_session() as session:
        run = get_run(session, run_id)
        if run is None:
            print(f"[!] Run ID {run_id} not found")
            return

        if not run.results:
            print(f"[!] Run ID {run_id} has no results")
            return

        # Calculate total cost for the run
        total_cost = sum(r.model_costs for r in run.results)
        max_steps = run.results[0].max_steps

        run_rows = [
            ["ID", str(run.id)],
            ["Created", _human_ts(run.created_at)],  # type: ignore[arg-type]
            ["Comment", run.comment or ""],  # type: ignore[misc]
            ["Parent LogDir", run.parent_logdir],
            ["# Results", str(len(run.results))],
            ["# Success", str(sum(1 for r in run.results if r.success))],
            ["Total Cost ($)", f"{total_cost:.4f}"],
        ]
        print("RUN SUMMARY")
        print(_build_table(run_rows))
        print()

        res_rows = [
            [
                str(r.id),
                r.eval_name,
                "✔" if r.success else "✘",
                f"{r.steps}/{r.max_steps}",
                r.model_name,
                f"{r.model_costs:.4f}",
                r.log_filepath,
                _human_ts(r.created_at),
            ]
            for r in run.results
        ]
        if res_rows:
            headers = [
                "ID",
                "Eval Name",
                "Ok?",
                "Steps",
                "Model",
                "Cost ($)",
                "Log FilePath",
                "Created",
            ]
            print(_build_table(res_rows, headers))
        else:
            print("<no child PentestResult rows>")
            return

        # Print step state legend and traces        
        print()
        print("STEP STATE LEGEND")
        legend_items = [f"{abbr}={state.value}" for state, abbr in StepStateAbbr.items()]
        print(" | ".join(legend_items))
        print()

        # Find the maximum width of abbreviations for padding
        max_abbr_width = max(len(abbr) for abbr in StepStateAbbr.values())

        print("STEP TRACES")
        
        # Group results by eval_name
        results_by_eval = defaultdict(list)
        for result in run.results:
            results_by_eval[result.eval_name].append(result)
        
        # Print results grouped by eval name
        for eval_name, results in results_by_eval.items():
            print(f"\n{eval_name}:")
                        
            # Print header row with step numbers if there are any steps
            if max_steps > 0:
                # Calculate MAX_CELL size with padding (longest abbrev + 2 for space on either side)
                max_cell_width = max_abbr_width + 2
                
                # Calculate the "Result .." string prefix using the longest result ID in this eval
                max_result_id = max(result.id for result in results)
                prefix = f"  Result {max_result_id} [T]: "
                prefix_len = len(prefix) - 1
                
                # Create header with step numbers aligned with columns
                header_parts = [" " * prefix_len]  # Space for the prefix
                for step_num in range(1, max_steps + 1):
                    step_header = str(step_num).center(max_cell_width)
                    header_parts.append(step_header)
                header = "|".join(header_parts)
                print(header)
                print("-" * len(header))
            
            for result in results:
                success = "T" if result.success else "F"
                ctxt = get_agent_ctxt(session, result.id)
                if ctxt and ctxt.steps():
                    step_abbrs = []
                    for step in ctxt.steps():
                        if step.step_type and step.step_type in StepStateAbbr:
                            abbr = StepStateAbbr[step.step_type]
                            step_abbrs.append(f" {abbr} ".center(max_cell_width))
                        else:
                            step_abbrs.append(" ? ".center(max_cell_width))
                    trace = "|".join(step_abbrs)
                    print(f"  Result {result.id} [{success}]: {trace}")
                else:
                    print(f"  Result {result.id} [{success}]: <no steps>")

# ------------------------------------------------------------------ #
# show-run-detailed
# ------------------------------------------------------------------ #
def show_run_detailed_cmd(args: Namespace) -> None:
    run_id = args.run_id

    with get_session() as session:
        run = get_run(session, run_id)
        if run is None:
            print(f"[!] Run ID {run_id} not found")
            return
        
        print(f"DETAILED STEPS FOR RUN {run_id} ({run.comment or 'no comment'})") # type: ignore[misc]
        
        if not run.results:
            print("<no child PentestResult rows>")
            return

        for result in run.results:
            print("\n" + ("-"*80))
            print(f"PENTEST RESULT {result.id}: {result.eval_name} {'(Success)' if result.success else '(Failure)'}")
            print(f"Log: {result.log_filepath}")
            print(f"Model: {result.model_name}, Cost: ${result.model_costs:.4f}")
            print("-" * 80)
            
            ctxt = get_agent_ctxt(session, result.id)
            if not ctxt:
                print("<no steps for this result>")
                continue

            headers = ["#", "Type", "Description"]
            rows = [
                [
                    str(step.step_num),
                    step.step_type or "",
                ]
                for step in ctxt.steps()
            ]
            print(_build_table(rows, headers, max_col=80))

def search_steps_cmd(args: Namespace) -> None:
    """
    Search for step‑type transitions in AgentStep rows.

    Required:
        --run-id RUN_ID      search all PentestResults in that run
            *or*
        --result-id RESULT_ID  search only that PentestResult

    Optional:
        --transition "S1 -> ... -> SN"
        --reflection     print reflection text
        --script         print script text
        --output         print execution_output text
        --steps A        return only step A
        --steps A B      return steps A through B (slice A:B)
    """
    if not args.run_id and not args.result_id:
        print("[!] Either --run-id or --result-id is required")
        return

    with get_session() as session:
        # 1. Collect matching results -----------------------------------------
        results: list[PentestResultORM] = []
        if args.run_id:
            run = get_run(session, args.run_id)
            if run is None:
                print(f"[!] Run ID {args.run_id} not found")
                return
            results.extend(run.results)

        if args.result_id:
            res = (
                session.query(PentestResultORM)
                .filter(PentestResultORM.id == args.result_id)
                .first()
            )
            if res is None:
                print(f"[!] PentestResult ID {args.result_id} not found")
                return
            results.append(res)

        if not results:
            print("<no PentestResult rows to search>")
            return

        # 2. Render each result -----------------------------------------------
        parts: list[str] = []
        total_groups = 0

        for i, r in enumerate(results, start=1):
            steps = get_agent_ctxt(session, r.id) or []
            if not steps:
                continue

            # Apply step filtering if --steps argument provided
            if hasattr(args, "steps") and args.steps:
                if len(args.steps) == 1:
                    # Single step index
                    step_idx = args.steps[0] - 1
                    if 0 <= step_idx < len(steps.steps()):
                        filtered_steps = [steps.steps()[step_idx]]
                    else:
                        continue  # Skip if index out of range
                elif len(args.steps) == 2:
                    # Step range slice
                    start_idx, end_idx = args.steps[0] - 1, args.steps[1] + 1
                    filtered_steps = steps.steps()[start_idx:end_idx]
                else:
                    filtered_steps = steps.steps()
                
                # Create a new AgentContext-like object with filtered steps
                from types import SimpleNamespace
                filtered_context = SimpleNamespace()
                filtered_context.steps = lambda: filtered_steps
                steps = filtered_context

            body, n_groups = search_steps(steps, args)
            if not body:
                continue

            total_groups += n_groups
            header = "\n".join(
                [
                    "=" * 40 + f"MATCH {i} " + "=" * 40,
                    f"PENTEST RESULT {r.id}  |  {r.eval_name}",
                    f"Model: {r.model_name}  |  Cost: ${r.model_costs:.4f}",
                    "=" * 80,
                ]
            )
            parts.extend([header, body])

        # 3. Final output ------------------------------------------------------
        final_out = "\n".join(parts)
        print(final_out)
        print(f"Total groups returned: {total_groups}")
        print(f"Total tokens: {get_token_count(final_out)}")

def label_steps_cmd(args: Namespace) -> None:
    """Re-label AgentStep rows for an existing PentestResult or all results in a Run.

    The command accepts *either* ``--run-id`` (label every result in that run)
    or ``--result-id`` (label only that single result).  For each selected
    ``PentestResult`` the original steps (``group_id = 0``) are passed through
    the same ``LabelAgentSteps`` flow that the online agent uses.  The
    resulting labels are persisted as a **new** ``group_id`` so that the
    original data remain untouched.  The new ``group_id`` is computed as
    ``max(existing_group_ids) + 1``.
    """

    if not getattr(args, "run_id", None) and not getattr(args, "result_id", None):
        print("[!] Either --run-id or --result-id is required")
        return

    step_labeler = LabelAgentSteps()
    lm_model = openai_o4_mini()
    with get_session() as session:
        # ------------------------------------------------------------------
        # 1. Collect target PentestResult rows
        # ------------------------------------------------------------------
        results: List[PentestResultORM] = []

        if getattr(args, "run_id", None):
            run = get_run(session, args.run_id)
            if run is None:
                print(f"[!] Run ID {args.run_id} not found")
                return
            results.extend(run.results)

        if getattr(args, "result_id", None):
            res = (
                session.query(PentestResultORM)
                .filter(PentestResultORM.id == args.result_id)
                .first()
            )
            if res is None:
                print(f"[!] PentestResult ID {args.result_id} not found")
                return
            results.append(res)

        if not results:
            print("<no PentestResult rows found>")
            return

        total_labeled = 0

        print(f"[+] Labeling {len(results)} PentestResult row(s)")

        # ------------------------------------------------------------------
        # 2. Iterate results – label & persist
        # ------------------------------------------------------------------
        for res in results:
            # Fetch *original* steps (group_id = 0)
            ctxt = get_agent_ctxt(session, int(res.id), group_id=0)  # type: ignore[arg-type]
            if not ctxt:
                continue

            agent_steps = ctxt.steps()

            # Invoke the LLM labeler
            try:
                step_types = step_labeler.invoke(lm_model, prompt_args={"results": agent_steps})  # type: ignore[arg-type]
                step_list_raw = cast(Any, step_types)
                print("STEPS:")
                for step in step_list_raw.steps:
                    print(f"Step {step.step_num}: {step.type}")

                if not step_types.steps:
                    print("No steps to label")
                    return
            except Exception as exc:
                print(f"[!] Failed to label steps for result {res.id}: {exc}")
                continue

            # Determine next group_id for this result
            max_gid = session.query(func.max(AgentStepORM.group_id)).filter(
                AgentStepORM.pentest_result_id == int(res.id)
            ).scalar() or 0
            new_gid = max_gid + 1

            # Persist new AgentStep rows with labels and new group_id
            opik_prompt_name, opik_prompt_commit = step_labeler.get_opik_prompt_info()
            create_agent_steps(
                session,
                agent_steps,
                step_list_raw.steps,  # type: ignore[attr-defined]
                int(res.id),
                opik_prompt_name,
                opik_prompt_commit,
                group_id=new_gid,
            )

            total_labeled += 1
        
        print(f"[+] Labeled steps for {total_labeled} PentestResult row(s). New group_id(s) added.")
        print(f"Total cost: ${lm_model.get_cost():.4f}")

def compare_steps_cmd(args: Namespace) -> None:
    """Display all AgentStep groups for a given PentestResult (or every
    result in a Run) so they can be compared side-by-side.

    The command accepts *either* ``--run-id`` or ``--result-id`` and renders
    the steps grouped by their ``group_id``.  Each group is annotated with
    the Opik prompt name & commit stored on ``ResultsGroupId`` so that any
    differences caused by prompt changes are immediately visible.
    """

    if not getattr(args, "run_id", None) and not getattr(args, "result_id", None):
        print("[!] Either --run-id or --result-id is required")
        return

    with get_session() as session:
        # ------------------------------------------------------------------
        # Resolve the set of PentestResult rows we need to display
        # ------------------------------------------------------------------
        results: list[PentestResultORM] = []

        if getattr(args, "run_id", None):
            run = get_run(session, args.run_id)
            if run is None:
                print(f"[!] Run ID {args.run_id} not found")
                return
            results.extend(run.results)

        if getattr(args, "result_id", None):
            res = (
                session.query(PentestResultORM)
                .filter(PentestResultORM.id == args.result_id)
                .first()
            )
            if res is None:
                print(f"[!] PentestResult ID {args.result_id} not found")
                return
            results.append(res)

        if not results:
            print("<no PentestResult rows found>")
            return

        # ------------------------------------------------------------------
        # Render each result with all of its step groups
        # ------------------------------------------------------------------
        for res in results:
            print("\n" + "=" * 80)
            print(
                f"PENTEST RESULT {res.id}: {res.eval_name} "
                f"({'Success' if res.success else 'Failure'})"
            )
            print(f"Model: {res.model_name}, Cost: ${res.model_costs:.4f}")
            print("-" * 80)

            groups_data = get_agent_steps(session, int(res.id))
            if not groups_data:
                print("<no agent steps found>")
                continue

            for grp, steps in groups_data:
                prompt_label = (
                    f"{grp.opik_prompt_name or ''} @ {grp.opik_prompt_commit or '—'}"
                ).strip()
                header_title = f"GROUP {grp.group_id} • {prompt_label}"
                print("\n" + header_title)
                print("~" * len(header_title))

                headers = ["#", "Type", "Reflection"]
                rows = [
                    [
                        str(step.step_number),
                        step.step_type or "",
                        (step.reflection or "")[:80],  # truncate for readability
                    ]
                    for step in steps
                ]
                print(_build_table(rows, headers, max_col=80))

# ------------------------------------------------------------------ #
# cost
# ------------------------------------------------------------------ #
def cost_cmd(args: Namespace) -> None:
    with get_session() as session:
        today_cost, week_cost, per_model = get_cost_summary(session)

    print("\nCOST SUMMARY (UTC)")
    print("------------------")
    print(f"Total cost TODAY       : $ {today_cost:.4f}")
    print(f"Total cost THIS WEEK   : $ {week_cost:.4f}\n")

    if per_model:
        headers = ["Model", "Total Cost ($)", "Total Steps", "Avg/Step ($)"]
        rows = [
            [model, f"{total:.4f}", str(steps), f"{avg:.6f}"]
            for model, total, steps, avg in per_model
        ]
        print("PER-MODEL AVERAGES")
        print(_build_table(rows, headers))
    else:
        print("<no PentestResult rows in database>")


# ------------------------------------------------------------------ #
# delete-runs
# ------------------------------------------------------------------ #
def delete_runs_cmd(args: Namespace) -> None:
    """Delete one or more runs by ID.
    
    Can delete a single run or a range of runs (inclusive).
    """
    from pentest_bot.db.tables.agent import delete_run
    
    run_ids = args.run_ids
    
    if len(run_ids) == 1:
        # Single run deletion
        run_id = run_ids[0]
        with get_session() as session:
            if delete_run(session, run_id):
                print(f"[+] Deleted run {run_id}")
            else:
                print(f"[!] Run {run_id} not found")
    elif len(run_ids) == 2:
        # Range deletion
        start_id, end_id = run_ids
        if start_id > end_id:
            print(f"[!] Invalid range: {start_id} > {end_id}")
            return
        
        deleted_count = 0
        not_found_count = 0
        
        with get_session() as session:
            for run_id in range(start_id, end_id + 1):
                if delete_run(session, run_id):
                    deleted_count += 1
                    print(f"[+] Deleted run {run_id}")
                else:
                    not_found_count += 1
                    print(f"[!] Run {run_id} not found")
        
        print(f"\nSummary: {deleted_count} runs deleted, {not_found_count} not found")
    else:
        print("[!] Please provide either 1 run ID or 2 run IDs (start end)")


# ---------------------------------------------------------------------------
# NEW: ad‑hoc SQL execution command
# ---------------------------------------------------------------------------

def q_db_cmd(args: Namespace) -> None:
    """Execute a raw SQL query against the selected database.

    This command is primarily intended for read‑only `SELECT` statements but
    will also execute `INSERT`, `UPDATE`, or `DELETE` operations.  For write
    queries the transaction is committed automatically and the affected row
    count is reported.
    """
    from sqlalchemy import text

    sql = " ".join(args.sql)

    with get_session() as session:
        result = session.execute(text(sql))

        if result.cursor is not None:  # type: ignore[attr-defined]
            rows_raw = result.fetchall()
            if not rows_raw:
                print("<empty result set>")
                return

            headers = list(result.keys())
            rows = [["" if cell is None else str(cell) for cell in row] for row in rows_raw]
            print(_build_table(rows, headers))
        else:  # Data‑modifying query
            session.commit()
            print(f"[+] Query OK, {result.rowcount} rows affected.") # type: ignore[attr-defined]

# ---------------------------------------------------------------------------
# Argument parsing & main entry‑point
# ---------------------------------------------------------------------------
def _build_parser() -> ArgumentParser:
    p = ArgumentParser(description="ASCII CLI for PentestBot SQLite database")
    p.add_argument("--db", help="Path to alternate pentest_bot.sqlite file")
    p.add_argument("--out", type=str, help="Optional filepath to redirect output to.")

    sub = p.add_subparsers(dest="cmd", required=True)

    # list‑runs ------------------------------------------------------------- #
    list_p = sub.add_parser("list-runs", help="List recent runs")
    list_p.set_defaults(func=list_runs_cmd)
    list_p.add_argument("--all", action="store_true", help="Show *all* runs including non-eval runs (ignore --limit)")
    list_p.add_argument("--limit", type=int, default=10, help="Max rows (default: 10)")

    # show‑run -------------------------------------------------------------- #
    show_p = sub.add_parser("show-run", help="Show a single run in detail")
    show_p.set_defaults(func=show_run_cmd)
    show_p.add_argument("run_id", type=int, help="ID of the Run to display")

    # show-run-detailed ----------------------------------------------------- #
    show_detailed_p = sub.add_parser("show-run-detailed", help="Show detailed steps for each result in a run")
    show_detailed_p.set_defaults(func=show_run_detailed_cmd)
    show_detailed_p.add_argument("run_id", type=int, help="ID of the Run to display")

    # show-steps ------------------------------------------------------------ #
    steps_p = sub.add_parser("search-steps", help="Search for step-type transitions in AgentStep rows")
    steps_p.set_defaults(func=search_steps_cmd)
    steps_p.add_argument("--run-id", type=int, help="Search all PentestResults in that run")
    steps_p.add_argument("--result-id", type=int, help="Search only that PentestResult")
    steps_p.add_argument("--transition", type=str, help="Transition pattern like 'S1 -> S2 -> ... -> SN'")
    steps_p.add_argument("--reflection", action="store_true", help="Print reflection text")
    steps_p.add_argument("--script", action="store_true", help="Print script text")
    steps_p.add_argument("--output", action="store_true", help="Print add_to_scratchpad text")
    steps_p.add_argument("--steps", type=int, nargs="+", help="Step indices to return (e.g. 1 2 3)")

    # label-steps ----------------------------------------------------------- #
    label_p = sub.add_parser("label-steps", help="Label steps for a PentestResult or all results in a Run")
    label_p.set_defaults(func=label_steps_cmd)
    label_p.add_argument("--run-id", type=int, help="Label all PentestResults in that run")
    label_p.add_argument("--result-id", type=int, help="Label only that PentestResult")

    # compare-steps --------------------------------------------------------- #
    cmp_p = sub.add_parser("compare-steps", help="Display all step groups for one result or every result in a run")
    cmp_p.set_defaults(func=compare_steps_cmd)
    cmp_p.add_argument("--run-id", type=int, help="Display every result in the run")
    cmp_p.add_argument("--result-id", type=int, help="Display only this PentestResult")

    # delete-runs ----------------------------------------------------------- #
    delete_p = sub.add_parser("delete-runs", help="Delete one or more runs by ID")
    delete_p.set_defaults(func=delete_runs_cmd)
    delete_p.add_argument("run_ids", type=int, nargs="+", help="Run ID(s) to delete. Single ID or start/end range (inclusive)")

    # q_db ------------------------------------------------------------------ #
    q_p = sub.add_parser("q_db", help="Execute raw SQL against the database")
    q_p.set_defaults(func=q_db_cmd)
    q_p.add_argument("sql", nargs="+", help="SQL query to execute (wrap in quotes if it contains spaces)")

    # cost ------------------------------------------------------------------ #
    cost_p = sub.add_parser("cost", help="Show usage costs and per-model averages")
    cost_p.set_defaults(func=cost_cmd)

    return p

@contextmanager
def _maybe_redirect_stdout(filepath: str | None):
    """A context manager that redirects stdout to a file if a path is provided."""
    if filepath:
        with open(filepath, "w", encoding="utf-8") as f:
            with redirect_stdout(f):
                yield
    else:
        yield

def main(argv: Sequence[str] | None = None) -> None:  # pragma: no‑cover
    parser = _build_parser()
    args = parser.parse_args(argv)
    with _maybe_redirect_stdout(args.out):
        args.func(args)  # type: ignore[attr-defined]


if __name__ == "__main__":
    main() 