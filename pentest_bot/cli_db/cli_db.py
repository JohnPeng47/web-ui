from __future__ import annotations

from argparse import ArgumentParser
from contextlib import contextmanager, redirect_stdout
from typing import Sequence

# import CLI command implementations from dedicated modules
from pentest_bot.cli_db.cmds.list_runs import list_runs_cmd
from pentest_bot.cli_db.cmds.show_run import show_run_cmd
from pentest_bot.cli_db.cmds.search_steps import search_steps_cmd
from pentest_bot.cli_db.cmds.label_steps import process_run_cmd
from pentest_bot.cli_db.cmds.compare_steps import compare_steps_cmd
from pentest_bot.cli_db.cmds.delete.cli import delete_cmd
from pentest_bot.cli_db.cmds.cost.cli import cost_cmd

# ---------------------------------------------------------------------------
# Argument parsing & main entry‑point
# ---------------------------------------------------------------------------
def _build_parser() -> ArgumentParser:
    p = ArgumentParser(description="ASCII CLI for PentestBot SQLite database")
    p.add_argument("--db", help="Path to alternate pentest_bot.sqlite file")
    p.add_argument("--out", type=str, help="Optional filepath to redirect output to.")

    sub = p.add_subparsers(dest="cmd", required=True)

    # list‑runs ------------------------------------------------------------- #
    list_p = sub.add_parser("list-runs", help="List recent runs")
    list_p.set_defaults(func=list_runs_cmd)
    list_p.add_argument("--all", action="store_true", help="Show *all* runs including non-eval runs (ignore --limit)")
    list_p.add_argument("--limit", type=int, default=10, help="Max rows (default: 10)")

    # show‑run -------------------------------------------------------------- #
    show_p = sub.add_parser("show-run", help="Show a single run in detail")
    show_p.set_defaults(func=show_run_cmd)
    show_p.add_argument("run_id", type=int, help="ID of the Run to display")

    # show-steps ------------------------------------------------------------ #
    steps_p = sub.add_parser("search-steps", help="Search for step-type transitions in AgentStep rows")
    steps_p.set_defaults(func=search_steps_cmd)
    steps_p.add_argument("--run-id", type=int, help="Search all PentestResults in that run")
    steps_p.add_argument("--result-ids", type=int, nargs="*", help="Search only that PentestResult")
    steps_p.add_argument("--transition", type=str, help="Transition pattern like 'S1 -> S2 -> ... -> SN'")
    steps_p.add_argument("--reflection", action="store_true", help="Print reflection text")
    steps_p.add_argument("--script", action="store_true", help="Print script text")
    steps_p.add_argument("--output", action="store_true", help="Print add_to_scratchpad text")
    steps_p.add_argument("--json", action="store_true", help="Output reflection, script, and output as JSON")
    steps_p.add_argument("--eval-name", type=str, help="Search the N most recent results matching eval-name")
    steps_p.add_argument("-n", "--n", type=int, default=5, help="How many eval-name results to pull (default 5)")
    steps_p.add_argument("--steps", nargs="+", type=int, help="Slice [a b] (inclusive, 1-based)")

    # label-steps ----------------------------------------------------------- #
    label_p = sub.add_parser("label", help="Label steps for a PentestResult or all results in a Run")
    label_p.set_defaults(func=process_run_cmd)
    label_p.add_argument("mode", type=str, help="Mode to run", choices=["steps", "solution"])
    label_p.add_argument("--run-id", type=int, help="Label all PentestResults in that run")
    label_p.add_argument("--result-id", type=int, help="Label only that PentestResult")

    # cost ----------------------------------------------------------------- #
    cost_p = sub.add_parser("cost", help="Display cost summary")
    cost_p.set_defaults(func=cost_cmd)

    # compare-steps --------------------------------------------------------- #
    cmp_p = sub.add_parser("compare-steps", help="Display all step groups for one result or every result in a run")
    cmp_p.set_defaults(func=compare_steps_cmd)
    cmp_p.add_argument("--run-id", type=int, help="Display every result in the run")
    cmp_p.add_argument("--result-id", type=int, help="Display only this PentestResult")
    cmp_p.add_argument("--eval-name", type=str, help="Display all results for this eval_name")

    # delete --------------------------------------------------------------- #
    del_p = sub.add_parser("delete", help="Delete runs or result groups")
    del_p.set_defaults(func=delete_cmd)
    del_p.add_argument("--run-ids", type=int, nargs="*", help="Run ID(s) to delete. Provide 1 or start end inclusive range")
    del_p.add_argument("--result-id", type=int, help="PentestResult ID when deleting group IDs")
    del_p.add_argument("--group-ids", type=int, nargs="*", help="Group ID(s) to delete. Provide 1 or start end inclusive range")

    return p

@contextmanager
def _maybe_redirect_stdout(filepath: str | None):
    """A context manager that redirects stdout to a file if a path is provided."""
    if filepath:
        with open(filepath, "w", encoding="utf-8") as f:
            with redirect_stdout(f):
                yield
    else:
        yield

def main(argv: Sequence[str] | None = None) -> None:  # pragma: no‑cover
    parser = _build_parser()
    args = parser.parse_args(argv)
    with _maybe_redirect_stdout(args.out):
        args.func(args)  # type: ignore[attr-defined]


if __name__ == "__main__":
    main() 