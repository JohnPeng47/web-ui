"""repair results_group_ids + sqlite-safe finalize

Revision ID: 54be2e05759a
Revises: 41b583c5a8a7_fix
Create Date: 2025-07-24 14:48:24.684923

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '20250724_repair_groups'
down_revision: Union[str, Sequence[str], None] = 'be44afdeb392'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade():
    conn = op.get_bind()
    insp = sa.inspect(conn)

    tables = set(insp.get_table_names())
    has_group_table = "results_group_ids" in tables

    # 1) ensure table results_group_ids exists
    if not has_group_table:
        op.create_table(
            "results_group_ids",
            sa.Column("id", sa.Integer(), primary_key=True, autoincrement=True),
            sa.Column(
                "pentest_result_id",
                sa.Integer(),
                sa.ForeignKey("pentest_results.id", ondelete="CASCADE"),
                nullable=False,
            ),
            sa.Column("group_id", sa.Integer(), nullable=False, index=True),
            sa.Column(
                "created_at",
                sa.DateTime(),
                nullable=False,
                server_default=sa.text("CURRENT_TIMESTAMP"),
            ),
            sa.Column("opik_prompt_name", sa.String(), nullable=True),
            sa.Column("opik_prompt_commit", sa.String(), nullable=True),
        )

    # reflect again after potential create
    meta = sa.MetaData()
    meta.reflect(bind=conn, only=("agent_steps", "results_group_ids"))
    agent_steps = meta.tables["agent_steps"]
    results_group_ids = meta.tables["results_group_ids"]

    # 2) ensure agent_steps.results_group_id exists + FK
    cols = {c["name"] for c in insp.get_columns("agent_steps")}
    if "results_group_id" not in cols:
        op.add_column(
            "agent_steps",
            sa.Column("results_group_id", sa.Integer(), nullable=True, index=True),
        )
        op.create_foreign_key(
            "fk_agent_steps_results_group_id",
            "agent_steps",
            "results_group_ids",
            ["results_group_id"],
            ["id"],
            ondelete="CASCADE",
        )

    # 3) populate results_group_id where it is NULL
    null_count = conn.execute(
        sa.select(sa.func.count())
        .select_from(agent_steps)
        .where(agent_steps.c.results_group_id.is_(None))
    ).scalar_one()

    if null_count:
        # build a map for existing groups (if table pre-existed)
        existing_groups = conn.execute(
            sa.select(
                results_group_ids.c.id,
                results_group_ids.c.pentest_result_id,
                results_group_ids.c.group_id,
                results_group_ids.c.opik_prompt_name,
                results_group_ids.c.opik_prompt_commit,
            )
        ).fetchall()

        group_map: dict[tuple[int, int, str | None, str | None], int] = {}
        for r in existing_groups:
            key = (
                r.pentest_result_id,
                r.group_id,
                r.opik_prompt_name,
                r.opik_prompt_commit,
            )
            # keep first seen id for that key
            group_map.setdefault(key, r.id)

        # find distinct step groups that still need a group row
        sel = sa.select(
            agent_steps.c.pentest_result_id,
            agent_steps.c.group_id,
            sa.func.min(agent_steps.c.created_at).label("created_at"),
            agent_steps.c.opik_prompt_name,
            agent_steps.c.opik_prompt_commit,
        ).where(
            agent_steps.c.results_group_id.is_(None)
        ).group_by(
            agent_steps.c.pentest_result_id,
            agent_steps.c.group_id,
            agent_steps.c.opik_prompt_name,
            agent_steps.c.opik_prompt_commit,
        )

        for r in conn.execute(sel):
            key = (
                r.pentest_result_id,
                r.group_id,
                r.opik_prompt_name,
                r.opik_prompt_commit,
            )
            rgid = group_map.get(key)
            if rgid is None:
                res = conn.execute(
                    results_group_ids.insert().values(
                        pentest_result_id=r.pentest_result_id,
                        group_id=r.group_id,
                        created_at=r.created_at,
                        opik_prompt_name=r.opik_prompt_name,
                        opik_prompt_commit=r.opik_prompt_commit,
                    )
                )
                rgid = res.inserted_primary_key[0]
                group_map[key] = rgid

            conn.execute(
                agent_steps.update()
                .where(
                    sa.and_(
                        agent_steps.c.pentest_result_id == r.pentest_result_id,
                        agent_steps.c.group_id == r.group_id,
                        agent_steps.c.opik_prompt_name == r.opik_prompt_name,
                        agent_steps.c.opik_prompt_commit == r.opik_prompt_commit,
                        agent_steps.c.results_group_id.is_(None),
                    )
                )
                .values(results_group_id=rgid)
            )

    # 4) finalize: make results_group_id NOT NULL and drop old opik_* cols (if still present)
    #    Use batch_alter_table so SQLite can recreate under the hood.
    cols = {c["name"] for c in insp.get_columns("agent_steps")}
    with op.batch_alter_table("agent_steps", recreate="always") as batch:
        batch.alter_column(
            "results_group_id",
            existing_type=sa.Integer(),
            nullable=False,
        )
        if "opik_prompt_name" in cols:
            batch.drop_column("opik_prompt_name")
        if "opik_prompt_commit" in cols:
            batch.drop_column("opik_prompt_commit")


def downgrade():
    # reverse the batch NOT NULL and add the per-step opik fields back
    with op.batch_alter_table("agent_steps", recreate="always") as batch:
        batch.add_column(sa.Column("opik_prompt_name", sa.String(), nullable=True))
        batch.add_column(sa.Column("opik_prompt_commit", sa.String(), nullable=True))
        batch.alter_column(
            "results_group_id",
            existing_type=sa.Integer(),
            nullable=True,
        )

    # no need to drop the results_group_ids table automatically in downgrade here;
    # if you want to, you can add it (and also null out results_group_id) â€“ omitted for brevity.
