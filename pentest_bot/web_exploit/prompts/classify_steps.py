import enum
from typing import List, Dict, Optional, TYPE_CHECKING

from opik.api_objects.prompt.types import PromptType
from pydantic import BaseModel

from src.llm_models import openai_o3_mini
from src.llm_provider import LMP, LMPVerificationException

from pentest_bot.models.steps import StepState, AgentStep
from .base import Prompt

class Step(BaseModel):
    step_num: int
    type: StepState

class StepList(BaseModel):
    num_steps: int
    steps: List[Step]

    def __str__(self):
        return "\n".join([f"{step.step_num}: {step.type}" for step in self.steps])

class LabelAgentSteps(LMP):
    prompt = "classify-steps"
    response_format = StepList

    def _prepare_prompt(self, templates={}, manual_rewrite: bool = False, **prompt_args) -> str:
        results: List[AgentStep] = prompt_args.pop("results")
        results_str = "\n".join([res.result() for res in results])

        prompt_args["trace"] = results_str
        return super()._prepare_prompt(prompt_args)
        
    def _verify_or_raise(self, res: StepList, **prompt_args):
        results: List[AgentStep] = prompt_args.pop("results")

        for ret_step, result_step in zip(res.steps, results):
            if ret_step.step_num != result_step.step_num:
                raise LMPVerificationException

# TODO:
# Write a prompt to check for the following:
# - check that if exploit = True, then the browser_check_xss tool was actually used

class ClassifyStepsPrompt(Prompt):
    name: str = "classify-steps"
    prompt: str = """
{{trace}}

Above is the execution trace of pentesting agent. Your task is to classify each according to the following step transition scheme:

INVESTIGATION States:
* Most of the time, the agent will be in one of the INVESTIGATION states 
* In these states, the agent is actively interacting with the web application via scripts attempting to uncover a vulnerability
* The agent will take some action each turn via the script 
* There are 3 investigation states, listed here in order of increasing likelihood of exploitation
PROBING: The agent is searching for presence of a vulnerability but nothing in the application response suggests any anomalous. At this point, exploitation is unlikely
SUSPECT: The initial probing stage has elicited behavior that warrants further investigation. At this point, exploitation is 50/50
PROMISING: After futher investigation, the potential to convert the suspect into a promising vulnerability is high
* To escalate from a lower state to a higher state, there MUST be a response from the application that *increases* the likelihood of a potential vulnerability

PIVOT States:
* The current investigative route has proven unfruitful and the agent is pivoting to a new approach
SOFT_PIVOT: the agent is pivoting off of the current investigative track but still targeting the same scope
HARD_PIVOT: the agent is pivoting off of the current investigative track and changing the scope as well

Error States:
ERROR: Something went wrong with the script execution

Here are a couple of steps that demonstrate the different step labels:
ie. 
- [PROBING] "Collected homepage HTML, identified forms and links with parameters for XSS"
- [SUSPECT] "Reflected input does not escape HTML chars"
- [SUSPECT]  "Injected single quote into ?sort= parameter; server returned SQL error"
- [PROMISING]  "Payload triggered 5 seconds more delay than baseline, query influenced by user input"
- [SOFT_PIVOT]  "Brute-force auth endpoint showed rate limiting; switching to token refresh flow within same login scope"
- [HARD_PIVOT]  "No vulns in account subsystem after 8 steps; shifting investigation to public blog comments feature"
- [HARD_PIVOT]  "Leaving user-profile XSS path; beginning enumeration of file-upload API for unrestricted upload"
* Return a list of the agent steps labeled with the appropriate state
"""
    type: PromptType = PromptType.JINJA2

