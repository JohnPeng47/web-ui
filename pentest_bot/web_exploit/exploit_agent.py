from typing import List, Tuple, Callable, Dict
from pydantic import BaseModel

from src.llm_models import LLMHub

from pentest_bot.web_exploit.base_agent import LaunchPentestBots, AGENT_PROMPT
from scripts.portswigger.data import PORT_SWIGGER_LABS, PROMPT_TEMPLATES

from pentest_bot.web_exploit.tools.browser_check import create_browser_check_xss
from pentest_bot.web_exploit.utils import unroll_iter_labs

class PortSwiggerLabInfo(BaseModel):
    url: str
    vuln_class: str
    lab_ind: int
    iters: int

    @property
    def name(self) -> str:
        return f"{self.vuln_class}_{self.lab_ind}"


class LaunchExploitLab(LaunchPentestBots):
    def _prepare_lab(self, url: str,  lab_info: PortSwiggerLabInfo) -> Tuple[str, Callable[[], bool], Dict]:
        vuln_class = lab_info.vuln_class    
        lab_ind = lab_info.lab_ind

        labs = PORT_SWIGGER_LABS[vuln_class]
        key = "with_description" if self.include_description else "without_description"
        problem_statement = PROMPT_TEMPLATES[vuln_class][key]

        if vuln_class == "cross_site_scripting":
            browser_check_template, check_cb, target_url = create_browser_check_xss()
            if self.include_description:
                problem_statement = problem_statement.format(
                    url=url,
                    description=labs[lab_ind].get("description", ""),
                    target_url=target_url,
                )
            else:
                problem_statement = problem_statement.format(url=url, target_url=target_url)

            eval_fn = check_cb
        else:
            eval_fn = labs[lab_ind].get("eval_fn")

        return problem_statement, eval_fn, browser_check_template

if __name__ == "__main__":
    import argparse
    
    LOG_FOLDER = "xss_agent"
    MAX_STEPS = 16
    MAX_ITERS = 3
    LLM_FUNCS = {
        "agent": {
            "agent": "o3"
        },
        "runner": {
            "step_labeler": "o4-mini"
        }
    }

    parser = argparse.ArgumentParser(description="Run PentestBot labs")
    parser.add_argument("--eval", action="store_true", help="Persist results to DB")
    parser.add_argument("--comment", "-m",type=str, help="Comment describing this run")
    args = parser.parse_args()

    if args.eval and not args.comment:
        raise ValueError("--comment is required when --eval is set")

    LAB_URLS = [
        PortSwiggerLabInfo(
            url="https://0a8f00470370901e806dbdb70038001d.web-security-academy.net/", 
            vuln_class="cross_site_scripting", 
            lab_ind=11, 
            iters=MAX_ITERS
        ),
        
        PortSwiggerLabInfo(
            url="https://0ae300e704cc95d280c5036d00de0073.web-security-academy.net/", 
            vuln_class="cross_site_scripting", 
            lab_ind=18,   
            iters=MAX_ITERS
        ),
        
        PortSwiggerLabInfo(
            url="https://0a9b002b03358bce818d6bce001000cd.web-security-academy.net/", 
            vuln_class="cross_site_scripting", 
            lab_ind=10, 
            iters=MAX_ITERS
        ),
        
        PortSwiggerLabInfo(
            url="https://0a8d00ef044559e181b2523f003900fb.web-security-academy.net/", 
            vuln_class="cross_site_scripting", 
            lab_ind=12, 
            iters=MAX_ITERS
        ),
    ]

    # TODO: configure a tools use interface on init ???
    bots = LaunchExploitLab(
        lab_urls=unroll_iter_labs(LAB_URLS),
        model=LLMHub(function_map=LLM_FUNCS["runner"]),
        agent_funcs=LLM_FUNCS["agent"],
        agent_prompt=AGENT_PROMPT,
        max_steps=MAX_STEPS,
        include_description=False,
        log_subfolder=LOG_FOLDER,
        is_eval=args.eval,
        comment=args.comment,
        # label_steps=True,
    )
    bots.start_labs()



