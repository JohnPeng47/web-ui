from typing import List, Tuple, Callable, Dict, Optional

from playwright.sync_api import sync_playwright

from pentest_bot.web_exploit.base_agent import LaunchPentestBots, LabInfo, PentestSession
from pentest_bot.web_exploit.tools.browser_check import TOOLS_TEMPLATE as browser_tool_template
from pentest_bot.web_exploit.prompts import DISCOVERY_PROMPT
from pentest_bot.web_exploit.utils import unroll_iter_labs

from src.llm_models import LLMHub

CHROME_EXE_PATH = r"C:\Users\jpeng\AppData\Local\ms-playwright\chromium-1161\chrome-win\chrome.exe"
CHROME_PROFILE_PATH = r"C:\Users\jpeng\AppData\Local\Google\Chrome\User Data\Default"

class DiscoveryLabInfo(LabInfo):
    pass

class LaunchDiscoveryBots(LaunchPentestBots):
    def start_pentest_session(self, 
                              problem_statement: str, 
                              eval_fn: Callable[[], bool], 
                              agent_tools: Dict, 
                              agent_prompt_full: str,
                              thread_id: int):
        with sync_playwright() as p:
            pw_context = p.chromium.launch_persistent_context(
                executable_path=CHROME_EXE_PATH,
                user_data_dir=CHROME_PROFILE_PATH,
            )
            context_var_name = f"pw_context{thread_id}"

            interpreter = self.interp_cls(shared_globals={context_var_name: pw_context})
            interpreter.set_prompt(f"""
In your python scripting environment, you have access to an instance of *synchronous* PlayWright BrowserContext under the variable name "{context_var_name}"
You should interact with the web application in your scripts only by using {context_var_name}.request: 
ie. 
{context_var_name}.request.get("https://example.com")
{context_var_name}.request.post("https://example.com", data={{"key": "value"}})
...
""")
            session = PentestSession(
                problem_stmt=problem_statement,
                model=self.model,
                agent_prompt=agent_prompt_full,
                max_steps=self.max_steps,
                eval_fn=eval_fn,
                tools=agent_tools,
                interpreter=interpreter,
            )
            session.run()
            return session

    def _prepare_lab(self, url: str, lab_info: DiscoveryLabInfo) -> Tuple[Optional[str], Callable[[], bool], Dict, Dict]:
        problem_statement = """
Do light recon for a pentest for {url}

Go for a breadth first approach, doing a broad sweep over all functionalities rather than tunneling in on any particular one
""".format(url=lab_info.url)
        eval_fn = None
        browser_tool_template = {}

        return problem_statement, eval_fn, browser_tool_template

if __name__ == "__main__":
    import argparse

    LLM_FUNCS = {
        "agent": "o3"
    }
    MAX_STEPS = 10

    parser = argparse.ArgumentParser(description="Run PentestBot labs")
    parser.add_argument("--eval", action="store_true", help="Persist results to DB")
    parser.add_argument("--comment", "-m",type=str, help="Comment describing this run")
    args = parser.parse_args()

    if args.eval and not args.comment:
        raise ValueError("--comment is required when --eval is set")

    LAB_URLS: List[DiscoveryLabInfo] = [
        DiscoveryLabInfo(
            url="https://app.aikido.dev", 
            name="aikido", 
            lab_ind=0, 
            iters=1, 
        ),
    ]

    bots = LaunchDiscoveryBots(
        lab_urls=unroll_iter_labs(LAB_URLS),
        model=LLMHub(function_map=LLM_FUNCS),
        agent_prompt=DISCOVERY_PROMPT,
        max_steps=MAX_STEPS,
        include_description=False,
        log_subfolder="discovery_agent",
        is_eval=args.eval,
        comment=args.comment,
    )
    bots.start_labs()
