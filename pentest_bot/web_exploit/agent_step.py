from typing import List, Dict, Optional, TYPE_CHECKING
import enum

from pydantic import BaseModel

from src.llm_models import openai_o3_mini
from src.llm_provider import LMP, LMPVerificationException

from pentest_bot.models.steps import StepState, AgentStep

class TransitionGraph:
    pass

class Step(BaseModel):
    step_num: int
    type: StepState

class StepList(BaseModel):
    num_steps: int
    steps: List[Step]

    def __str__(self):
        return "\n".join([f"{step.step_num}: {step.type}" for step in self.steps])

class LabelAgentSteps(LMP):
    prompt = "classify-steps"
    response_format = StepList

    def _prepare_prompt(self, templates={}, manual_rewrite: bool = False, **prompt_args) -> str:
        results: List[AgentStep] = prompt_args.pop("results")
        results_str = "\n".join([res.result() for res in results])

        prompt_args["trace"] = results_str
        return super()._prepare_prompt(prompt_args)
        
    def _verify_or_raise(self, res: StepList, **prompt_args):
        results: List[AgentStep] = prompt_args.pop("results")

        for ret_step, result_step in zip(res.steps, results):
            if ret_step.step_num != result_step.step_num:
                raise LMPVerificationException