from typing import List, Dict, Optional

from src.llm_models import openai_o3_mini
from src.llm_provider import LMP, LMPVerificationException
import enum

from pydantic import BaseModel

class AgentStep(BaseModel):
    """LLM response schema expected by :pymeth:`PentestBot.invoke`."""

    reflection: str
    script: str
    add_to_scratchpad: Optional[str] = None

    def is_complete(self) -> bool:  # noqa: D401 – imperative mood
        """Return *True* iff the agent signalled task completion."""

        return "TASK_COMPLETE" in self.script or "TASK_COMPLETE" in self.reflection
    
class AgentResult(AgentStep):
    step_num: int
    execution_output: str

    def result(self) -> str:
        return f"Step {self.step_num}: {self.reflection}\nScript Output: {self.execution_output}"


CRITIC_PROMPT = """
{trace}

Above is the execution trace of pentesting agent. Your task is provide a summary of the trace.
You output the following:
- Group together agent steps in which a consistent goal is being pursued
- Identify anything that the agent finds interesting, and the context around it
- Identify the following errors or mistakes if they occur:
--> The agent makes an incorrect inference from a previous observation
--> The agent repeatedly stuck in a loop over an action that has low EV for finding an exploitable vulnerability

Be terse and concise in your output, but make sure to not omit key information
Finally, make a determination if the agent should continue investigating along its current path
"""

class StepState(str, enum.Enum):
    PROBING = "PROBING"
    SUSPECT = "SUSPECT"
    PROMISING = "PROMISING"
    SOFT_PIVOT = "SOFT_PIVOT"
    HARD_PIVOT = "HARD_PIVOT"

class Step(BaseModel):
    step_num: int
    summary: str
    type: StepState

class StepList(BaseModel):
    num_steps: int
    steps: List[Step]

    def __str__(self):
        return "\n".join([f"{step.step_num}: {step.type}" for step in self.steps])

# TODO: rewrite to move verification here
class LabelAgentSteps(LMP):
    prompt = """
{{trace}}

Above is the execution trace of pentesting agent. Your task is to classify each according to the following step transition scheme:

INVESTIGATION States:
* Most of the time, the agent will be in one of investigation states
* Each INVESTIGATION is scoped to a particular part of the application. This "part" is usually something on the scale of a single parameter or a set of query parameters, and should not be as broad as the whole page of an application
PROBING: The agent is searching for presence of a vulnerability but nothing in the application response suggests any anomalous. At this point, exploitation is unlikely
SUSPECT: The initial probing stage has elicited behavior that warrants further investigation. At this point, exploitation is 50/50
PROMISING: After futher investigation, the potential to convert the suspect into a promising vulnerability is high

PIVOT States:
* The current investigative route has proven unfruitful and the agent is pivoting to a new approach
SOFT_PIVOT: the agent is pivoting off of the current investigative track but still targeting the same scope
HARD_PIVOT: the agent is pivoting off of the current investigative track and changing the scope as well

Output Format:
* Attach a short summary of the agent's reflection for each step
> The summary should highlight the key reasoning behind the step classification
ie. 
- [PROBING] "Collected homepage HTML, identified forms and links with parameters for XSS"
- [SUSPECT] "Reflected input does not escape HTML chars"
- [SUSPECT]  "Injected single quote into ?sort= parameter; server returned SQL error"
- [PROMISING]  "Payload triggered 5 seconds more delay than baseline, query influenced by user input"
- [SOFT_PIVOT]  "Brute-force auth endpoint showed rate limiting; switching to token refresh flow within same login scope"
- [HARD_PIVOT]  "No vulns in account subsystem after 8 steps; shifting investigation to public blog comments feature"
- [HARD_PIVOT]  "Leaving user-profile XSS path; beginning enumeration of file-upload API for unrestricted upload"
* Return a list of the agent steps labeled with the appropriate state
"""
    response_format = StepList

    def _prepare_prompt(self, templates={}, manual_rewrite: bool = False, **prompt_args) -> str:
        results: List[AgentResult] = prompt_args.pop("results")
        results_str = "\n".join([res.result() for res in results])

        prompt_args["trace"] = results_str
        return super()._prepare_prompt(prompt_args)
        
    def _verify_or_raise(self, res: StepList, **prompt_args):
        results: List[AgentResult] = prompt_args.pop("results")

        for ret_step, result_step in zip(res.steps, results):
            if ret_step.step_num != result_step.step_num:
                raise LMPVerificationException
            
if __name__ == "__main__":
    from pentest_bot.db import get_session, get_steps_for_result, get_run

    with get_session() as session:
        model = openai_o3_mini()
        runs = [r.id for r in get_run(session, 25).results]
        for r in runs:
            steps = get_steps_for_result(session, r)
            trace = "\n".join([f"{i}: {s.reflection}" for i, s in enumerate(steps, start=1)]) 
            print(trace)
            print(LabelAgentSteps().invoke(model, prompt_args={"results": trace}))
        
        # steps = get_steps_for_result(session, 18)
        # trace = "\n".join([f"{i}: {s.reflection}" for i, s in enumerate(steps, start=1)]) 
        # print(trace)      
        # model = openai_o3_mini()

        # for i in range(3):
        #     print(LabelAgentSteps().invoke(model, prompt_args={"trace": trace}))

        # model_4o = openai_4o()
        # # print("RAW:::")
        # # for i in range(3):
        # #     print(summarize_trace(model, trace))
        # # print("STRUCTURED:::")
        # for i in range(1):
        #     print("---------------o3_mini-----------------")
        #     print(LabelAgentSteps().invoke(model, prompt_args={"trace": trace}))
        #     # print("---------------4o-----------------")
        #     # print(LabelAgentSteps().invoke(model_4o, prompt_args={"trace": trace}))

        # # steps = LabelAgentSteps().invoke(model, prompt_args={"trace": trace})
        # # print(steps)