import asyncio
import logging
import threading

from pydantic import BaseModel
from typing import Optional, Callable

from cnc.services.exploit.agent_pool import AgentPool, PentestSession
from pentest_bot.web_exploit.tools import PythonInterpreter
from pentest_bot.web_exploit.prompts.exploit_agent import AGENT_PROMPT_ORIGINAL
from common.prompt import PromptConfig, PromptStrategy

from eval.harness.exploit.queue import PersistedQueue
from src.detection.prompts import ScheduledAction

from common.constants import MAX_EXPLOIT_AGENT_STEPS

LOGGER_NAME = "agentlog"

class AgentStartConfig(BaseModel):
    problem_statement: str
    eval_fn: Optional[Callable[[], bool]]
    max_steps: int

    def __str__(self):
        output = ""
        output += f"Problem Statement: {self.problem_statement}\n"
        output += f"Max Steps: {self.max_steps}\n"
        return output

class EvalAgentPool(AgentPool["AgentStartConfig"]):
    """
    AgentPool that consumes work from a BroadCastChannel constructed from Serialized Data
    Subscribes to the channel, pops each item, converts it to AgentStartConfig,
    then enqueues an agent run with start_agent(request).

    You must implement convert_req(self, item: Q) -> AgentStartConfig.
    """
    def __init__(
        self,
        *,
        channel: "PersistedQueue[ScheduledAction]",
        queue_fp: str,
        llm_config: dict,
        max_workers: Optional[int] = None,
        log_subfolder: str = "pentest_bot",
        interp_cls: type[PythonInterpreter] = PythonInterpreter,
        label_steps: bool = False,
    ):
        super().__init__(
            llm_config=llm_config,
            max_workers=max_workers,
            log_subfolder=log_subfolder,
            interp_cls=interp_cls,
            label_steps=label_steps,
        )
        self._channel = channel
        self._queue_fp = queue_fp
        # Each pool instance keeps its own subscription queue
        self._sub_queue: asyncio.Queue[ScheduledAction] = self._channel.subscribe()

        # Bookkeeping for the consumer task
        self._consumer_task: Optional[asyncio.Task] = None
        self._consumer_lock = threading.Lock()

    # ----------------------- Channel consumption -----------------------

    def start_channel_consumer(self) -> asyncio.Task:
        """
        Start the async consumer that pulls from the BroadcastChannel subscription
        and enqueues agent runs. Returns the created asyncio.Task.

        You must call this from within a running event loop.
        """
        with self._consumer_lock:
            if self._consumer_task is not None and not self._consumer_task.done():
                raise RuntimeError("Channel consumer already running.")
            loop = asyncio.get_running_loop()

            loop.create_task(self._channel.fill_from_file(self._queue_fp, ScheduledAction))
            self._consumer_task = loop.create_task(self._consume_queue())
            return self._consumer_task

    def stop_channel_consumer(self) -> None:
        """
        Cancel the consumer task if it is running. This is a best-effort stop.
        """
        with self._consumer_lock:
            if self._consumer_task is not None and not self._consumer_task.done():
                self._consumer_task.cancel()

    async def _consume_queue(self) -> None:
        """
        Core loop: await queue items, convert, and enqueue agent runs.
        Relies on AgentPool.start_agent for execution and tracking.
        """
        log = logging.getLogger(LOGGER_NAME)
        print("Consuming queue, qsize: ", self._sub_queue.qsize())

        while self._sub_queue.qsize() > 0:
            item = await self._sub_queue.get()
            try:
                request = await self.convert_req(item)
                print(request)
            except Exception:
                log.exception("convert_req failed; dropping item.")
                self._sub_queue.task_done()
                continue

            # try:
            #     run_id = self.start_agent(request)
            #     log.info("Enqueued run_id %s from broadcast item.", run_id)
            # except Exception:
            #     log.exception("start_agent failed for broadcast item.")
            # finally:
            #     self._sub_queue.task_done()

    # ----------------------- Required conversion hook -----------------------
    async def convert_req(self, item: ScheduledAction) -> "AgentStartConfig":
        """
        Convert a queueObject into an AgentStartConfig.
        Implement this in your subclass or monkey-patch it in tests.
        """
        problem_statement = f"""
Here is a description of the vulnerability:
{item.vulnerability_description}

Here is the HTTP message that is related to the vulnerability:
{await item.page_item.to_str()}
""" 
        return AgentStartConfig(
            problem_statement=problem_statement,
            eval_fn=None,
            max_steps=MAX_EXPLOIT_AGENT_STEPS
        )

    # ----------------------- Agent construction -----------------------

    def start_pentest_session(self, request: "AgentStartConfig") -> PentestSession:
        """
        Build and run a PentestSession for a single lab/request.
        """
        # TODO: only tool we need is the xss_check_tool
        # with BrowserClient() as ctx:
        #     fetch_tool_template = create_browser_fetch_tool(ctx)
        #     xss_check_tool_template, check_cb, target_url = create_browser_check_xss_tool(ctx)
        #     tools = {**xss_check_tool_template, **fetch_tool_template}

        tools: dict = {}
        interpreter = self.interp_cls(shared_globals=tools)

        session = PentestSession(
            model_config=self.llm_config["model_config"],
            prompt_config=PromptConfig(
                strategy=PromptStrategy.MANUAL,
                prompt=AGENT_PROMPT_ORIGINAL
            ),
            problem_stmt=request.problem_statement,
            max_steps=request.max_steps,
            eval_fn=request.eval_fn,
            interpreter=interpreter,
        )
        session.run()
        return session


async def main(queue_path: str):
    vuln_queue = PersistedQueue()

    MAX_WORKERS = 4
    LLM_CONFIG = {
        "prompt_config":{
            "agent": {
                "name": "xss_agent",
                "commit": "247b8187"
            },
            "classify-steps": {
                "name": "classify-steps",
            }
        },
        "model_config": {
            "classify-steps": "o4-mini",
            "agent": "o3"
        }
    }

    agent_pool = EvalAgentPool(
        channel=vuln_queue,
        queue_fp=queue_path,
        llm_config=LLM_CONFIG,
        max_workers=MAX_WORKERS
    )
    agent_pool.start_channel_consumer()


if __name__ == "__main__":
    import asyncio
    from eval.datasets.detection import PAGE_DATA_JSON, VULN_QUEUE_JSON
    
    from .queue import PersistedQueue
    from src.detection.prompts import ScheduledAction

    asyncio.run(main(VULN_QUEUE_JSON))

