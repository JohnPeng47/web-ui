from __future__ import annotations

import concurrent.futures
import logging
import os
import signal
import sys
import threading
import uuid
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, List, Optional, Type, TypeVar, Generic, Callable


from enum import Enum
from pydantic import BaseModel

from pentest_bot.web_exploit.agent import PentestSession
from pentest_bot.db.tables.exploit_agent import AgentStepORM as AgentStepORM, PentestResultORM

# interpreter and tools
from pentest_bot.web_exploit.tools import PythonInterpreter
from pentest_bot.web_exploit.tools.browser_tools import create_browser_check_xss_tool, create_browser_fetch_tool
from pentest_bot.web_exploit.tools.browser import BrowserClient
from pentest_bot.models.steps import AgentStep, StepState as LLMStep

from logger import (
    create_log_dir_or_noop,
    get_agent_loggers,
    run_id_dir,
    setup_agent_logger,
)
from src.llm_models import LLMHub
from src.utils import set_ctxt_id

agent_log, full_log = get_agent_loggers()

# Optional request type for your agents. Replace or specialize as needed.
T = TypeVar("T")

LOGGER_NAME = "agentlog"
MAX_OUTPUT_LOG_LEN = 8192  # characters
DEFAULT_MAX_AGENT_STEPS = 12

class AgentRunState(str, Enum):
    PENDING = "PENDING"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    CANCELED = "CANCELED"


class AgentRunResult(BaseModel):
    """
    What a finished agent returns. Adjust fields if your PentestSession exposes more.
    """
    success: bool
    steps: int
    max_steps: int
    model_name: str
    agent_steps: List[AgentStep]
    log_filepath: Optional[Path] = None


class AgentStatus(BaseModel):
    """
    Public status surface for a run ID.
    - state shows lifecycle
    - result appears once COMPLETED
    - error is set if FAILED
    """
    state: AgentRunState
    result: Optional[AgentRunResult] = None
    error: Optional[str] = None    

class AgentPool(ABC, Generic[T]):
    """
    A pool that accepts requests to launch abstract agents, tracks their status,
    and exposes a simple status/result API.

    Usage:
        class MyPool(AgentPool[LabInfo]):
            def start_pentest_session(self, request: LabInfo) -> PentestSession:
                return PentestSession(... build from request ...)

        pool = MyPool(llm_config=..., max_workers=8)
        run_id = pool.start_agent(LabInfo(url=..., name=..., lab_ind=0))
        status = pool.get_agent_status(run_id)
    """
    def __init__(
        self,
        *,
        llm_config: Dict,
        max_workers: Optional[int] = None,
        log_subfolder: str = "pentest_bot",
        # keep here ??
        interp_cls: Type[PythonInterpreter] = PythonInterpreter,
        label_steps: bool = False,
    ):
        self.interp_cls = interp_cls
        self.label_steps = label_steps

        # TODO: we probably need 
        parent_dir = create_log_dir_or_noop(log_dir=log_subfolder)
        self.parent_dir = run_id_dir(parent_dir)
        self.parent_dir.mkdir(parents=True, exist_ok=True)

        self.llm_config = llm_config
        self.model_router = LLMHub(llm_config["model_config"])

        self._executor: concurrent.futures.ThreadPoolExecutor = concurrent.futures.ThreadPoolExecutor(
            max_workers=max_workers
        )

        # Tracking
        self._lock = threading.Lock()
        self._futures: Dict[str, concurrent.futures.Future[AgentRunResult]] = {}
        self._statuses: Dict[str, AgentStatus] = {}
        self._logs: Dict[str, Optional[Path]] = {}

    # ----------------------- Public API -----------------------

    def update_status(self, run_id: str, state: AgentRunState, result: Optional[AgentRunResult] = None, error: Optional[str] = None) -> None:
        """
        Update the status of a specific agent run.
        """
        self._statuses[run_id] = AgentStatus(
            state=state,
            result=result,
            error=error,
        )

    def start_agent(self, request: T) -> str:
        """
        Queue a single agent run based on `request`.
        Returns a run_id you can use with get_agent_status.
        """
        run_id = str(uuid.uuid4())

        self.update_status(run_id, AgentRunState.PENDING)

        # Submit work
        future = self._executor.submit(self._run_agent, run_id, request)

        # REFACTOR: keep default done_cb but allow done_db specified via args
        def _done_cb(fut: concurrent.futures.Future[AgentRunResult]) -> None:
            try:
                result = fut.result()
                self.update_status(run_id, AgentRunState.COMPLETED, result=result)
            except Exception as e:
                logging.getLogger(LOGGER_NAME).exception("Run %s failed", run_id)
                self.update_status(run_id, AgentRunState.FAILED, error=str(e))

        future.add_done_callback(_done_cb)
        with self._lock:
            self._futures[run_id] = future
            # Mark RUNNING immediately after submission
            self.update_status(run_id, AgentRunState.RUNNING)

        return run_id

    def get_agent_status(self, run_id: str) -> AgentStatus:
        """
        Returns the status and, if completed, the AgentRunResult.
        Raises KeyError if run_id is unknown.
        """
        with self._lock:
            if run_id not in self._statuses:
                raise KeyError(f"Unknown run_id: {run_id}")
            status = self._statuses[run_id]

        # If still running, reflect live state without blocking
        if status.state in {AgentRunState.RUNNING, AgentRunState.PENDING}:
            # Optionally, you can enrich with partial logs or heartbeat here
            return status

        return status

    def shutdown(self, wait: bool = True, cancel_futures: bool = False) -> None:
        """
        Shut down the underlying executor. Call this when you are done with the pool.
        """
        self._executor.shutdown(wait=wait, cancel_futures=cancel_futures)
        logging.shutdown()

    @abstractmethod
    def start_pentest_session(
        self, 
        request: T
    ) -> PentestSession:
        """Starts a pentest session for a single lab"""
        raise NotImplementedError("Subclass must implement this method")

    def persist_results(
        self,
        *,
        run_id: str,
        log_filepath: Path,
        success: bool,
        steps: int,
        max_steps: int,
        model_name: str,
        agent_steps: List[AgentStep],
        session: PentestSession,
        model_router: LLMHub,
    ) -> None:
        """
        Optional: override to persist results to your DB, write summaries, etc.
        """
        return

    # -------------------- Internal machinery ------------------
    def _sigint(self):
        print("\n[!] SIGINT received – terminating thread pool …", file=sys.stderr)
        self._executor.shutdown(wait=False, cancel_futures=True)
        logging.shutdown()

        os._exit(1)

    def _install_sigint_handler(self) -> None:
        def _sigint(signum, frame):
            print("\n[!] SIGINT received – terminating thread pool …", file=sys.stderr)
            self._executor.shutdown(wait=False, cancel_futures=True)
            logging.shutdown()

            os._exit(1)
        signal.signal(signal.SIGINT, _sigint)

    def _run_agent(self, run_id: str, request: T) -> AgentRunResult:
        """
        Worker that configures per-run logging, builds the session, executes it,
        and returns a structured result.
        """
        set_ctxt_id(run_id)

        # Fresh model router per run so you can account for per-run costs if needed
        model_router = LLMHub(self.llm_config["model_config"])

        _, log_filepath = setup_agent_logger(
            LOGGER_NAME,
            parent_dir=self.parent_dir,
        )
        run_logger = logging.getLogger(LOGGER_NAME)
        run_logger.info("agent started: run_id %s", run_id)

        session = self.start_pentest_session(request)
        success, steps, max_steps, model_name = session.result()
        agent_steps = session.steps()

        # Persist if subclass implements it
        try:
            self.persist_results(
                run_id=run_id,
                log_filepath=log_filepath,
                success=success,
                steps=steps,
                max_steps=max_steps,
                model_name=model_name,
                agent_steps=agent_steps,
                session=session,
                model_router=model_router,
            )
        except Exception:
            run_logger.exception("persist_results failed for run_id %s", run_id)

        result = AgentRunResult(
            success=success,
            steps=steps,
            max_steps=max_steps,
            model_name=model_name,
            agent_steps=agent_steps,
            log_filepath=log_filepath,
        )
        return result
