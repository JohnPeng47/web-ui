{
  "reported_to": "GitLab",
  "reported_by": "vakzz ",
  "title": "RCE via the DecompressedArchiveSizeValidator and Project BulkImports (behind feature flag)",
  "content": "\nSummary\nThe DecompressedArchiveSizeValidator is used to check the size of a archive before extracting it:\nhttps://gitlab.com/gitlab-org/gitlab/-/blob/v15.1.0-ee/lib/gitlab/import_export/decompressed_archive_size_validator.rb#L82\nCode 281 Bytes\n1      def command\n2        \"gzip -dc #{@archive_path} | wc -c\"\n3      end\n4\n5   def validate\n6        pgrp = nil\n7        valid_archive = true\n8\n9        Timeout.timeout(TIMEOUT_LIMIT) do\n10          stdin, stdout, stderr, wait_thr = Open3.popen3(command, pgroup: true)\n11          stdin.close\nSince command is a string and passed directly to Open3.popen3 it will be interpreted as a shell command, so if archive_path contains any special characters it can be used to run arbitrary commands.\nOne of the places that the DecompressedArchiveSizeValidator is used is in the Gitlab::ImportExport::FileImporter,\nCode 127 Bytes\n1     def size_validator\n2        @size_validator ||= DecompressedArchiveSizeValidator.new(archive_path: @archive_file)\n3      end\nIt gets @archive_file from the constructor, and is used by the Gitlab::ImportExport::Importer which gets it from project.import_source.\nUnder normal circumstances import_source is nil and is generated by the FileImporter using @archive_file = File.join(@shared.archive_path, Gitlab::ImportExport.export_filename(exportable: @importable)).\nMost of the places I've checked do not allow you to set the import_source for a project, or have the import_type set to something other than gitlab_project or gitlab_custom_project_template (which is required to use the ::Gitlab::ImportExport::Importer).\nThere is one place though, in the BulkImports::Projects::Pipelines::ProjectPipeline. Luckily this is disabled by default as it requires the bulk_import_projects feature to be enabled. If/once this feature is enabled, it's possible to trigger the above flow.\nThis is possible as the two transformer on the ProjectPipeline are :BulkImports::Common::Transformers::ProhibitedAttributesTransformer and ::BulkImports::Projects::Transformers::ProjectAttributesTransformer, which first removes a list of prohibited keys:\nCode 324 Bytes\n1PROHIBITED_REFERENCES = Regexp.union(\n2          /\\Acached_markdown_version\\Z/,\n3          /\\Aid\\Z/,\n4          /_id\\Z/,\n5          /_ids\\Z/,\n6          /_html\\Z/,\n7          /attributes/,\n8          /\\Aremote_\\w+_(url|urls|request_header)\\Z/ # carrierwave automatically creates these attribute methods for uploads\n9        ).freeze\nAnd then sets a few other values:\nCode 535 Bytes\n1          entity = context.entity\n2          visibility = data.delete('visibility')\n3\n4          data['name'] = entity.destination_name\n5          data['path'] = entity.destination_name.parameterize\n6          data['import_type'] = PROJECT_IMPORT_TYPE\n7          data['visibility_level'] = Gitlab::VisibilityLevel.string_options[visibility] if visibility.present?\n8          data['namespace_id'] = Namespace.find_by_full_path(entity.destination_namespace)&.id if entity.destination_namespace.present?\n9\n10          data.transform_keys!(&:to_sym)\nAll of the other params are allowed and passed directly into project = ::Projects::CreateService.new(context.current_user, data).execute. The first thing the create service does its to check if it's creating from a template, and if so the CreateFromTemplateService is used instead:\nhttps://gitlab.com/gitlab-org/gitlab/-/blob/v15.1.0-ee/app/services/projects/create_service.rb#L25-27\nCode 280 Bytes\n1    def execute\n2     if create_from_template?\n3        return ::Projects::CreateFromTemplateService.new(current_user, params).execute\n4      end\n5    # ...\n6    end\n7\n8    def create_from_template?\n9      @params[:template_name].present? || @params[:template_project_id].present?\n10    end\nSince we control all of the params, this path can be triggered by setting template_name to a valid template such as rails. This then uses the GitlabProjectsImportService which allows the import_type to be changed from gitlab_project_migration to gitlab_project.\nhttps://gitlab.com/gitlab-org/gitlab/-/blob/v15.1.0-ee/app/services/projects/gitlab_projects_import_service.rb#L61-76\nCode 479 Bytes\n1    def prepare_import_params\n2      data = {}\n3      data[:override_params] = @override_params if @override_params\n4\n5      if overwrite_project?\n6        data[:original_path] = params[:path]\n7        params[:path] += \"-#{tmp_filename}\"\n8      end\n9\n10      if template_file\n11        data[:sample_data] = params.delete(:sample_data) if params.key?(:sample_data)\n12        params[:import_type] = 'gitlab_project'\n13      end\n14\n15      params[:import_data] = { data: data } if data.present?\n16    end\nThe Projects::CreateService service is then called again with the updated import_type, but the rest of our params the same. This causes the import_schedule to happen as @project.gitlab_project_migration? is no longer true\nhttps://gitlab.com/gitlab-org/gitlab/-/blob/v15.1.0-ee/app/services/projects/create_service.rb#L276-282\nCode 281 Bytes\n1    def import_schedule\n2      if @project.errors.empty?\n3        @project.import_state.schedule if @project.import? && !@project.bare_repository_import? && !@project.gitlab_project_migration?\n4      else\n5        fail(error: @project.errors.full_messages.join(', '))\n6      end\n7    end\nIf a custom import_source was used, it will be used as the @archive_file for the Gitlab::ImportExport::FileImporter. After wait_for_archived_file has reached MAX_RETRIES (it continues instead of failing) then validate_decompressed_archive_size will be called and then Open3.popen3 with a controllable string.\nhttps://gitlab.com/gitlab-org/gitlab/-/blob/v15.1.0-ee/lib/gitlab/import_export/file_importer.rb#L45\nCode 377 Bytes\n1       wait_for_archived_file do\n2          validate_decompressed_archive_size if Feature.enabled?(:validate_import_decompressed_archive_size)\n3          decompress_archive\n4        end\n5\n6      def wait_for_archived_file\n7        MAX_RETRIES.times do |retry_number|\n8          break if File.exist?(@archive_file)\n9\n10          sleep(2**retry_number)\n11        end\n12\n13        yield\n14      end\nSteps to reproduce\nspin up a gitlab instance\nssh in and enable bulk project imports with from a rails console: sudo gitlab-rails console then ::Feature.enable(:bulk_import_projects)\nstart watching the logs with sudo gitlab-ctl tail\ncreate an api token\ncreate a new group\ncreate a new project in that group\ndownload api_project_ql.py (F1785226) and change PROJECT_PATH to the full path of the project above and PROJECT_ID to its id\nchange \"import_source\":\"/tmp/ggg;echo lala|tee /tmp/1234;#\", to be your custom command (it cannot contain > as json will convert it to \\u003c)\n(optional) remove proxies={\"http\":\"http://127.0.0.1:8080\", \"https\":\"http://127.0.0.1:8080\"} if you are not using burp/another proxy\nrun it with FLASK_APP=api_project_ql.py flask run\nstart ngrok with ngrok http 5000\ngo to new group -> import group\nenter the ngrok http address and your token from above in the Import groups from another instance of GitLab section\nselect the group created above, change the parent to No parent and choose a new group name\nhit import\nyou should see requests being made, then after the project is imported and the wait_for_archived_file has timed out (takes a few minutes) you should see something like following error in the logs and the payload will execute:\nCode 244 Bytes\n1command exited with error code 2: tar (child): /tmp/ggg;echo lala|tee /tmp/1234;#: Cannot open: No such file or directory\n2tar (child): Error is not recoverable: exiting now\n3tar: Child returned status 2\n4tar: Error is not recoverable: exiting now\nCode 54 Bytes\n1vagrant@gitlab:~$ cat /tmp/1234\n2lala\n3vagrant@gitlab:~$\nImpact\nIf the bulk_import_projects feature is enabled, allows an attacker to execute arbitrary commands on a gitlab server\nWhat is the current bug behavior?\nThe DecompressedArchiveSizeValidator passes a string to popen that can contain attacker controlled data\nThe ProjectPipeline does not correctly filter the project params\nWhat is the expected correct behavior?\nThe DecompressedArchiveSizeValidator should use Gitlab::Popen and the command should be an array of strings\nThe ProjectPipeline should use the Gitlab::ImportExport::AttributeCleaner or just have a whitelist of allowed params\nRelevant logs and/or screenshots\nCode 1.93 KiB\n1{\n2    \"severity\": \"ERROR\",\n3    \"time\": \"2022-06-23T01:52:57.556Z\",\n4    \"correlation_id\": \"0d72e54e82938b4b82aa3dcafe6c4dfe\",\n5    \"exception.class\": \"Gitlab::ImportExport::Error\",\n6    \"exception.message\": \"command exited with error code 2: tar (child): /tmp/ggg;echo lala|tee /tmp/1234;#: Cannot open: No such file or directory\\ntar (child): Error is not recoverable: exiting now\\ntar: Child returned status 2\\ntar: Error is not recoverable: exiting now\",\n7    \"user.username\": \"vakzz\",\n8    \"tags.program\": \"sidekiq\",\n9    \"tags.locale\": \"en\",\n10    \"tags.feature_category\": \"importers\",\n11    \"tags.correlation_id\": \"0d72e54e82938b4b82aa3dcafe6c4dfe\",\n12    \"extra.sidekiq\": {\n13        \"retry\": false,\n14        \"queue\": \"repository_import\",\n15        \"version\": 0,\n16        \"backtrace\": 5,\n17        \"dead\": false,\n18        \"status_expiration\": 86400,\n19        \"memory_killer_memory_growth_kb\": 50,\n20        \"memory_killer_max_memory_growth_kb\": 300000,\n21        \"args\": [\n22            \"31\"\n23        ],\n24        \"class\": \"RepositoryImportWorker\",\n25        \"jid\": \"9d28590a58ec7db944453edc\",\n26        \"created_at\": 1655948922.4369478,\n27        \"correlation_id\": \"0d72e54e82938b4b82aa3dcafe6c4dfe\",\n28        \"meta.user\": \"vakzz\",\n29        \"meta.client_id\": \"user/2\",\n30        \"meta.caller_id\": \"BulkImports::PipelineWorker\",\n31        \"meta.remote_ip\": \"192.168.0.144\",\n32        \"meta.feature_category\": \"importers\",\n33        \"meta.root_caller_id\": \"Import::BulkImportsController#create\",\n34        \"meta.project\": \"imported_13/export_project\",\n35        \"meta.root_namespace\": \"imported_13\",\n36        \"worker_data_consistency\": \"always\",\n37        \"idempotency_key\": \"resque:gitlab:duplicate:repository_import:e64a87ccd733ff3c9b12cd20d98ea1d44a21196e9d0398c0af668ee84bf77358\",\n38        \"size_limiter\": \"validated\",\n39        \"enqueued_at\": 1655948922.442958\n40    },\n41    \"extra.importer\": \"Import/Export\",\n42    \"extra.exportable_id\": 31,\n43    \"extra.exportable_path\": \"imported_13/export_project\",\n44    \"extra.import_jid\": null\n45}\nOutput of checks\nResults of GitLab environment info\nCode 812 Bytes\n1System information\n2System:\t\tUbuntu 20.04\n3Proxy:\t\tno\n4Current User:\tgit\n5Using RVM:\tno\n6Ruby Version:\t2.7.5p203\n7Gem Version:\t3.1.4\n8Bundler Version:2.3.15\n9Rake Version:\t13.0.6\n10Redis Version:\t6.2.7\n11Sidekiq Version:6.4.0\n12Go Version:\tunknown\n13\n14GitLab information\n15Version:\t15.1.0-ee\n16Revision:\t31c24d2d864\n17Directory:\t/opt/gitlab/embedded/service/gitlab-rails\n18DB Adapter:\tPostgreSQL\n19DB Version:\t12.10\n20URL:\t\thttp://gitlab.wbowling.info\n21HTTP Clone URL:\thttp://gitlab.wbowling.info/some-group/some-project.git\n22SSH Clone URL:\tgit@gitlab.wbowling.info:some-group/some-project.git\n23Elasticsearch:\tno\n24Geo:\t\tno\n25Using LDAP:\tno\n26Using Omniauth:\tyes\n27Omniauth Providers:\n28\n29GitLab Shell\n30Version:\t14.7.4\n31Repository storage paths:\n32- default: \t/var/opt/gitlab/git-data/repositories\n33GitLab Shell path:\t\t/opt/gitlab/embedded/service/gitlab-shell\nImpact\nIf the bulk_import_projects feature is enabled, allows an attacker to execute arbitrary commands on a gitlab server.\n\n",
  "severity": [
    9.9,
    null
  ],
  "bounty": 33510,
  "weaknesses": [
    "Command Injection - Generic"
  ],
  "screenshots": {},
  "disclosed_date": 1663058400,
  "report_url": "https://hackerone.com/reports/1609965",
  "is_multi_component": true,
  "complexity": "MEDIUM",
  "novelty": "MEDIUM",
  "vuln_category": "WEB_APP",
  "steps": [
    [
      1,
      "Enable the bulk_import_projects feature flag in GitLab's Rails console"
    ],
    [
      2,
      "Use the Bulk Import feature to import a project with a malicious import_source parameter containing shell commands"
    ],
    [
      3,
      "Wait for the import process to reach the decompressed archive validation step"
    ],
    [
      4,
      "Observe command execution when the vulnerable validator processes the malicious input"
    ]
  ],
  "vuln_description": "The vulnerability allows remote code execution through improper shell command construction in the DecompressedArchiveSizeValidator when processing project imports via the Bulk Import feature. The validator passes untrusted input directly to a shell command via Open3.popen3, enabling command injection when the bulk_import_projects feature is enabled.",
  "reason": "This vulnerability requires understanding multiple complex components: the bulk import pipeline, project creation service, import/export validators, and their subtle interactions. The attacker must chain these components together while navigating feature flags and timing constraints. The command injection vector is non-obvious as it requires specific parameter manipulation through multiple transformation layers.",
  "new_complexity": "HIGH",
  "requires_code": true,
  "requires_CVE": false,
  "is_ctf": false,
  "other_report": null,
  "injection_metadata": {
    "is_simple_payload": false
  },
  "authnz_metadata": {
    "reason": "The vulnerability involves command injection via a feature flag (bulk_import_projects) and requires specific API calls that wouldn't be part of normal user navigation. The methodology focuses on authN/authZ boundaries within the same application context, not command injection vulnerabilities or feature flag exploitation.",
    "is_detectable": false
  }
}